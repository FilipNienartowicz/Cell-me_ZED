{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "RE_SPACES = re.compile(\"\\s+\")\n",
    "RE_HASHTAG = re.compile(\"[@#][_a-z0-9]+\")\n",
    "RE_EMOTICONS = re.compile(\"(:-?\\))|(:p)|(:d+)|(:-?\\()|(:/)|(;-?\\))|(<3)|(=\\))|(\\)-?:)|(:'\\()|(8\\))\")\n",
    "RE_HTTP = re.compile(\"http(s)?://[/\\.a-z0-9]+\")\n",
    "\n",
    "PRINT_EVERY = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep=',')\n",
    "train = train.drop(['Id','Product Name', 'Brand Name', 'Price'], axis = 1)\n",
    "train = train.replace(np.nan, '', regex=True)\n",
    "\n",
    "X = train.drop('Rating', axis = 1)\n",
    "y = train.Rating\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202646</td>\n",
       "      <td>Excelent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202647</td>\n",
       "      <td>Fit perfectly. Excelent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202648</td>\n",
       "      <td>It has a very good relation, price/performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202649</td>\n",
       "      <td>Like it a lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202650</td>\n",
       "      <td>Dear , i had a problem wich the wifi senial !!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202651</td>\n",
       "      <td>Received ok. Very good option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202652</td>\n",
       "      <td>It was expected. excellent presentation!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202653</td>\n",
       "      <td>excelente 100% recomendado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202654</td>\n",
       "      <td>We use it in Argentine. It works fantastic, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202655</td>\n",
       "      <td>Excellent Product. Excellent Vendor. I truly r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                            Reviews\n",
       "0  202646                                           Excelent\n",
       "1  202647                           Fit perfectly. Excelent.\n",
       "2  202648    It has a very good relation, price/performance.\n",
       "3  202649                                      Like it a lot\n",
       "4  202650  Dear , i had a problem wich the wifi senial !!...\n",
       "5  202651                      Received ok. Very good option\n",
       "6  202652           It was expected. excellent presentation!\n",
       "7  202653                         excelente 100% recomendado\n",
       "8  202654  We use it in Argentine. It works fantastic, fa...\n",
       "9  202655  Excellent Product. Excellent Vendor. I truly r..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\", sep=\",\")\n",
    "test = test.drop(['Product Name', 'Brand Name', 'Price'], axis = 1)\n",
    "test = test.replace(np.nan, '', regex=True)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        pass\n",
    "    \n",
    "class BeforeTokenizationNormalizer():\n",
    "    @staticmethod\n",
    "    def normalize(text):\n",
    "        text = text.strip().lower()\n",
    "        text = text.replace('&nbsp;', ' ')\n",
    "        text = text.replace('&lt;', '<')\n",
    "        text = text.replace('&gt;', '>')\n",
    "        text = text.replace('&amp;', '&')\n",
    "        text = text.replace('&pound;', u'£')\n",
    "        text = text.replace('&euro;', u'€')\n",
    "        text = text.replace('&copy;', u'©')\n",
    "        text = text.replace('&reg;', u'®')\n",
    "        return text\n",
    "    \n",
    "class SimpleTokenizer(Tokenizer):\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        return re.split(RE_SPACES, text)\n",
    "\n",
    "class NltkTokenizer(Tokenizer):\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        return nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "class CellTokenizer(Tokenizer):\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        tokens = SimpleTokenizer.tokenize(text)\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "            match = [RE_HASHTAG, RE_EMOTICONS, RE_HTTP]\n",
    "            tokenmatch = False\n",
    "            if match[0].search(token) is not None:\n",
    "                tokenmatch = True\n",
    "            if match[1].search(token) is not None:\n",
    "                tokenmatch = True\n",
    "            if match[2].search(token) is not None:\n",
    "                tokenmatch = True\n",
    "            if not tokenmatch:\n",
    "                del tokens[i]\n",
    "                tokens[i:i] = NltkTokenizer.tokenize(token)\n",
    "            i += 1\n",
    "            \n",
    "        ps = nltk.stem.PorterStemmer()\n",
    "        newTokens = []\n",
    "        for t in tokens:\n",
    "            newTokens.append(ps.stem(t))\n",
    "        return newTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182380\n",
      "0/182380\n",
      "2000/182380\n",
      "4000/182380\n",
      "6000/182380\n",
      "8000/182380\n",
      "10000/182380\n",
      "12000/182380\n",
      "14000/182380\n",
      "16000/182380\n",
      "18000/182380\n",
      "20000/182380\n",
      "22000/182380\n",
      "24000/182380\n",
      "26000/182380\n",
      "28000/182380\n",
      "30000/182380\n",
      "32000/182380\n",
      "34000/182380\n",
      "36000/182380\n",
      "38000/182380\n",
      "40000/182380\n",
      "42000/182380\n",
      "44000/182380\n",
      "46000/182380\n",
      "48000/182380\n",
      "50000/182380\n",
      "52000/182380\n",
      "54000/182380\n",
      "56000/182380\n",
      "58000/182380\n",
      "60000/182380\n",
      "62000/182380\n",
      "64000/182380\n",
      "66000/182380\n",
      "68000/182380\n",
      "70000/182380\n",
      "72000/182380\n",
      "74000/182380\n",
      "76000/182380\n",
      "78000/182380\n",
      "80000/182380\n",
      "82000/182380\n",
      "84000/182380\n",
      "86000/182380\n",
      "88000/182380\n",
      "90000/182380\n",
      "92000/182380\n",
      "94000/182380\n",
      "96000/182380\n",
      "98000/182380\n",
      "100000/182380\n",
      "102000/182380\n",
      "104000/182380\n",
      "106000/182380\n",
      "108000/182380\n",
      "110000/182380\n",
      "112000/182380\n",
      "114000/182380\n",
      "116000/182380\n",
      "118000/182380\n",
      "120000/182380\n",
      "122000/182380\n",
      "124000/182380\n",
      "126000/182380\n",
      "128000/182380\n",
      "130000/182380\n",
      "132000/182380\n",
      "134000/182380\n",
      "136000/182380\n",
      "138000/182380\n",
      "140000/182380\n",
      "142000/182380\n",
      "144000/182380\n",
      "146000/182380\n",
      "148000/182380\n",
      "150000/182380\n",
      "152000/182380\n",
      "154000/182380\n",
      "156000/182380\n",
      "158000/182380\n",
      "160000/182380\n",
      "162000/182380\n",
      "164000/182380\n",
      "166000/182380\n",
      "168000/182380\n",
      "170000/182380\n",
      "172000/182380\n",
      "174000/182380\n",
      "176000/182380\n",
      "178000/182380\n",
      "180000/182380\n",
      "182000/182380\n"
     ]
    }
   ],
   "source": [
    "words = Counter()\n",
    "\n",
    "print(len(X_train))\n",
    "i = 0\n",
    "for index, row in X_train.iterrows():\n",
    "    if not i % PRINT_EVERY: print(str(i) + '/' + str(len(X_train)))\n",
    "    i = i + 1\n",
    "    t = BeforeTokenizationNormalizer.normalize(row['Reviews'])\n",
    "    words.update(CellTokenizer.tokenize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52875"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = [',', '-', ';', \"''\", '...','.','!', '?', '(', ')', '``', ':']\n",
    "stopwords = [\"a\", \"about\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\",\n",
    "            \"before\", \"being\", \"between\", \"both\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"during\", \"each\",\n",
    "            \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\",\n",
    "            \"himself\", \"his\", \"how\", \"i\", \"in\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"let\", \"me\", \"more\", \"most\", \"my\",\n",
    "            \"myself\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"own\", \"sha\",\n",
    "            \"she\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\",\n",
    "            \"then\", \"there\", \"there's\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"until\", \"up\", \"very\",\n",
    "            \"was\", \"we\", \"were\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\",\"whom\", \"with\", \"would\", \"you\",\n",
    "            \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "            \"n't\", \"'s\", \"'ll\", \"'re\", \"'d\", \"'m\", \"'ve\",\n",
    "            \"above\", \"again\", \"against\", \"below\", \"but\", \"down\", \"few\", \"if\", \"nor\", \"off\",\n",
    "            \"out\", \"over\", \"same\", \"too\", \"under\", \"why\"]\n",
    "#\"cannot\", \"no\", \"not\"\n",
    "for word in list(words):\n",
    "    if word in ignore:\n",
    "        del words[word]\n",
    "    elif word in stopwords:\n",
    "        del words[word]\n",
    "        \n",
    "#words.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow(X, features):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "\n",
    "    i = 0\n",
    "    for index, rows in X.iterrows():\n",
    "        if not i % PRINT_EVERY: print(str(i) + '/' + str(len(X)))\n",
    "        \n",
    "        review = BeforeTokenizationNormalizer.normalize(rows['Reviews'])\n",
    "        review_tokens = CellTokenizer.tokenize(review)\n",
    "        for token in set(review_tokens):\n",
    "            if token not in features:\n",
    "                continue\n",
    "            row.append(i)\n",
    "            col.append(features[token])\n",
    "            data.append(1)\n",
    "        i = i + 1\n",
    "           \n",
    "    return csr_matrix((data, (row, col)), shape=(len(X), len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n",
      "0/182380\n",
      "10000/182380\n",
      "20000/182380\n",
      "30000/182380\n",
      "40000/182380\n",
      "50000/182380\n",
      "60000/182380\n",
      "70000/182380\n",
      "80000/182380\n",
      "90000/182380\n",
      "100000/182380\n",
      "110000/182380\n",
      "120000/182380\n",
      "130000/182380\n",
      "140000/182380\n",
      "150000/182380\n",
      "160000/182380\n",
      "170000/182380\n",
      "180000/182380\n"
     ]
    }
   ],
   "source": [
    "min_word_count = 10\n",
    "\n",
    "common_words = list([k for k, v in words.most_common() if v > min_word_count])\n",
    "feature_dict = {}\n",
    "for word in common_words:\n",
    "    feature_dict[word] = len(feature_dict)\n",
    "\n",
    "print(\"Training classifier...\")\n",
    "X_train_bow = create_bow(X_train, feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearRegression(n_jobs=-1)\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validating...\")\n",
    "X_valid_bow = create_bow(X_valid, feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Results ===================\n",
      "RMSE  0.9897077054442097\n"
     ]
    }
   ],
   "source": [
    "predicted_valid = classifier.predict(X_valid_bow)\n",
    "predicted_valid = np.around(predicted)\n",
    "predicted_valid = predicted.astype(int)\n",
    "predicted_valid[predicted_valid > 5] = 5\n",
    "predicted_valid[predicted_valid < 1] = 1\n",
    "\n",
    "print(\"=================== Results ===================\")\n",
    "print(\"RMSE \", math.sqrt(mean_squared_error(y_valid, predicted_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "0/211195\n",
      "10000/211195\n",
      "20000/211195\n",
      "30000/211195\n",
      "40000/211195\n",
      "50000/211195\n",
      "60000/211195\n",
      "70000/211195\n",
      "80000/211195\n",
      "90000/211195\n",
      "100000/211195\n",
      "110000/211195\n",
      "120000/211195\n",
      "130000/211195\n",
      "140000/211195\n",
      "150000/211195\n",
      "160000/211195\n",
      "170000/211195\n",
      "180000/211195\n",
      "190000/211195\n",
      "200000/211195\n",
      "210000/211195\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing...\")\n",
    "X_test = create_bow(test, feature_dict)\n",
    "predicted_test = classifier.predict(X_test)\n",
    "predicted_test = np.around(predicted)\n",
    "predicted_test = predicted_test.astype(int)\n",
    "\n",
    "predicted_test[predicted_test > 5] = 5\n",
    "predicted_test[predicted_test < 1] = 1\n",
    "test['Rating'] = predicted_test\n",
    "test.to_csv(\"submission.csv\", sep=\",\", columns = ['Id', 'Rating'], index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
