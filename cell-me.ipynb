{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "RE_SPACES = re.compile(\"\\s+\")\n",
    "RE_HASHTAG = re.compile(\"[@#][_a-z0-9]+\")\n",
    "RE_EMOTICONS = re.compile(\"(:-?\\))|(:p)|(:d+)|(:-?\\()|(:/)|(;-?\\))|(<3)|(=\\))|(\\)-?:)|(:'\\()|(8\\))\")\n",
    "RE_HTTP = re.compile(\"http(s)?://[/\\.a-z0-9]+\")\n",
    "\n",
    "PRINT_EVERY = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep=',')\n",
    "train = train.drop(['Id','Product Name', 'Brand Name', 'Price'], axis = 1)\n",
    "train = train.replace(np.nan, '', regex=True)\n",
    "\n",
    "X = train.drop('Rating', axis = 1)\n",
    "y = train.Rating\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202646</td>\n",
       "      <td>Excelent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202647</td>\n",
       "      <td>Fit perfectly. Excelent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202648</td>\n",
       "      <td>It has a very good relation, price/performance.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202649</td>\n",
       "      <td>Like it a lot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202650</td>\n",
       "      <td>Dear , i had a problem wich the wifi senial !!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202651</td>\n",
       "      <td>Received ok. Very good option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202652</td>\n",
       "      <td>It was expected. excellent presentation!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202653</td>\n",
       "      <td>excelente 100% recomendado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202654</td>\n",
       "      <td>We use it in Argentine. It works fantastic, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202655</td>\n",
       "      <td>Excellent Product. Excellent Vendor. I truly r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                            Reviews\n",
       "0  202646                                           Excelent\n",
       "1  202647                           Fit perfectly. Excelent.\n",
       "2  202648    It has a very good relation, price/performance.\n",
       "3  202649                                      Like it a lot\n",
       "4  202650  Dear , i had a problem wich the wifi senial !!...\n",
       "5  202651                      Received ok. Very good option\n",
       "6  202652           It was expected. excellent presentation!\n",
       "7  202653                         excelente 100% recomendado\n",
       "8  202654  We use it in Argentine. It works fantastic, fa...\n",
       "9  202655  Excellent Product. Excellent Vendor. I truly r..."
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\", sep=\",\")\n",
    "test = test.drop(['Product Name', 'Brand Name', 'Price'], axis = 1)\n",
    "test = test.replace(np.nan, '', regex=True)\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer():\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        pass\n",
    "    \n",
    "class BeforeTokenizationNormalizer():\n",
    "    @staticmethod\n",
    "    def normalize(text):\n",
    "        text = text.strip().lower()\n",
    "        text = text.replace('&nbsp;', ' ')\n",
    "        text = text.replace('&lt;', '<')\n",
    "        text = text.replace('&gt;', '>')\n",
    "        text = text.replace('&amp;', '&')\n",
    "        text = text.replace('&pound;', u'£')\n",
    "        text = text.replace('&euro;', u'€')\n",
    "        text = text.replace('&copy;', u'©')\n",
    "        text = text.replace('&reg;', u'®')\n",
    "        return text\n",
    "    \n",
    "class SimpleTokenizer(Tokenizer):\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        return re.split(RE_SPACES, text)\n",
    "\n",
    "class NltkTokenizer(Tokenizer):\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        return nltk.tokenize.word_tokenize(text)\n",
    "    \n",
    "class CellTokenizer(Tokenizer):\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        tokens = SimpleTokenizer.tokenize(text)\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "            match = [RE_HASHTAG, RE_EMOTICONS, RE_HTTP]\n",
    "            tokenmatch = False\n",
    "            if match[0].search(token) is not None:\n",
    "                tokenmatch = True\n",
    "            if match[1].search(token) is not None:\n",
    "                tokenmatch = True\n",
    "            if match[2].search(token) is not None:\n",
    "                tokenmatch = True\n",
    "            if not tokenmatch:\n",
    "                del tokens[i]\n",
    "                tokens[i:i] = NltkTokenizer.tokenize(token)\n",
    "            i += 1\n",
    "            \n",
    "        ps = nltk.stem.PorterStemmer()\n",
    "        newTokens = []\n",
    "        for t in tokens:\n",
    "            newTokens.append(ps.stem(t))\n",
    "        return newTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182380\n",
      "0/182380\n",
      "10000/182380\n",
      "20000/182380\n",
      "30000/182380\n",
      "40000/182380\n",
      "50000/182380\n",
      "60000/182380\n",
      "70000/182380\n",
      "80000/182380\n",
      "90000/182380\n",
      "100000/182380\n",
      "110000/182380\n",
      "120000/182380\n",
      "130000/182380\n",
      "140000/182380\n",
      "150000/182380\n",
      "160000/182380\n",
      "170000/182380\n",
      "180000/182380\n"
     ]
    }
   ],
   "source": [
    "words = Counter()\n",
    "\n",
    "print(len(X_train))\n",
    "i = 0\n",
    "for index, row in X_train.iterrows():\n",
    "    if not i % PRINT_EVERY: print(str(i) + '/' + str(len(X_train)))\n",
    "    i = i + 1\n",
    "    t = BeforeTokenizationNormalizer.normalize(row['Reviews'])\n",
    "    words.update(CellTokenizer.tokenize(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52875"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore = [',', '-', ';', \"''\", '...','.','!', '?', '(', ')', '``', ':']\n",
    "stopwords = [\"a\", \"about\", \"after\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\",\n",
    "            \"before\", \"being\", \"between\", \"both\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"during\", \"each\",\n",
    "            \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\",\n",
    "            \"himself\", \"his\", \"how\", \"i\", \"in\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"let\", \"me\", \"more\", \"most\", \"my\",\n",
    "            \"myself\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"own\", \"sha\",\n",
    "            \"she\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\",\n",
    "            \"then\", \"there\", \"there's\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"until\", \"up\", \"very\",\n",
    "            \"was\", \"we\", \"were\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\",\"whom\", \"with\", \"would\", \"you\",\n",
    "            \"your\", \"yours\", \"yourself\", \"yourselves\",\n",
    "            \"n't\", \"'s\", \"'ll\", \"'re\", \"'d\", \"'m\", \"'ve\",\n",
    "            \"above\", \"again\", \"against\", \"below\", \"but\", \"down\", \"few\", \"if\", \"nor\", \"off\",\n",
    "            \"out\", \"over\", \"same\", \"too\", \"under\", \"why\"]\n",
    "#\"cannot\", \"no\", \"not\"\n",
    "for word in list(words):\n",
    "    if word in ignore:\n",
    "        del words[word]\n",
    "    elif word in stopwords:\n",
    "        del words[word]\n",
    "        \n",
    "#words.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow(X, features):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "\n",
    "    i = 0\n",
    "    for index, rows in X.iterrows():\n",
    "        if not i % PRINT_EVERY: print(str(i) + '/' + str(len(X)))\n",
    "        \n",
    "        review = BeforeTokenizationNormalizer.normalize(rows['Reviews'])\n",
    "        review_tokens = CellTokenizer.tokenize(review)\n",
    "        for token in set(review_tokens):\n",
    "            if token not in features:\n",
    "                continue\n",
    "            row.append(i)\n",
    "            col.append(features[token])\n",
    "            data.append(1)\n",
    "        i = i + 1\n",
    "           \n",
    "    return csr_matrix((data, (row, col)), shape=(len(X), len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n",
      "0/182380\n",
      "10000/182380\n",
      "20000/182380\n",
      "30000/182380\n",
      "40000/182380\n",
      "50000/182380\n",
      "60000/182380\n",
      "70000/182380\n",
      "80000/182380\n",
      "90000/182380\n",
      "100000/182380\n",
      "110000/182380\n",
      "120000/182380\n",
      "130000/182380\n",
      "140000/182380\n",
      "150000/182380\n",
      "160000/182380\n",
      "170000/182380\n",
      "180000/182380\n"
     ]
    }
   ],
   "source": [
    "min_word_count = 10\n",
    "\n",
    "common_words = list([k for k, v in words.most_common() if v > min_word_count])\n",
    "feature_dict = {}\n",
    "for word in common_words:\n",
    "    feature_dict[word] = len(feature_dict)\n",
    "\n",
    "print(\"Training classifier...\")\n",
    "X_train_bow = create_bow(X_train, feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearRegression(n_jobs=-1)\n",
    "classifier.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "0/20265\n",
      "10000/20265\n",
      "20000/20265\n"
     ]
    }
   ],
   "source": [
    "print(\"Validating...\")\n",
    "X_valid_bow = create_bow(X_valid, feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================== Results ===================\n",
      "RMSE  0.9897077054442097\n"
     ]
    }
   ],
   "source": [
    "predicted_valid = classifier.predict(X_valid_bow)\n",
    "predicted_valid_r = np.around(predicted_valid)\n",
    "predicted_valid_r = predicted_valid_r.astype(int)\n",
    "predicted_valid_r[predicted_valid_r > 5] = 5\n",
    "predicted_valid_r[predicted_valid_r < 1] = 1\n",
    "\n",
    "print(\"=================== Results ===================\")\n",
    "print(\"RMSE \", math.sqrt(mean_squared_error(y_valid, predicted_valid_r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "0/211195\n",
      "10000/211195\n",
      "20000/211195\n",
      "30000/211195\n",
      "40000/211195\n",
      "50000/211195\n",
      "60000/211195\n",
      "70000/211195\n",
      "80000/211195\n",
      "90000/211195\n",
      "100000/211195\n",
      "110000/211195\n",
      "120000/211195\n",
      "130000/211195\n",
      "140000/211195\n",
      "150000/211195\n",
      "160000/211195\n",
      "170000/211195\n",
      "180000/211195\n",
      "190000/211195\n",
      "200000/211195\n",
      "210000/211195\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing...\")\n",
    "X_test = create_bow(test, feature_dict)\n",
    "predicted_test = classifier.predict(X_test)\n",
    "predicted_test_r = np.around(predicted_test)\n",
    "predicted_test_r = predicted_test_r.astype(int)\n",
    "\n",
    "predicted_test_r[predicted_test_r > 5] = 5\n",
    "predicted_test_r[predicted_test_r < 1] = 1\n",
    "test['Rating'] = predicted_test_r\n",
    "test.to_csv(\"submission.csv\", sep=\",\", columns = ['Id', 'Rating'], index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
